# AI Pentesting Playbook Template

> **Status:** Draft  
> **Category:** AI Security Pentesting  
> **Applies to:** LLMs / RAG / Agents / ML Pipelines  
> **Version:** v0.1  

---

## 1. Overview

### 1.1 Objective
Describe the security objective of this test.
- What capability is the attacker attempting to gain?
- What security boundary is being challenged?

### 1.2 Threat Model
Define:
- Attacker profile (external user, insider, API client, compromised service)
- Assumptions and constraints
- Trust boundaries

---

## 2. Target System Description

Describe the AI system under test:
- Model type(s)
- Deployment context (API, application, agent, batch)
- Access level required
- External integrations (tools, data sources, plugins)

---

## 3. Attack Preconditions

List required conditions:
- Authentication or authorization level
- Input channels available
- Tool or data access
- Environmental assumptions

---

## 4. Attack Methodology

### 4.1 Technique Description
Explain the attack technique in plain language.

### 4.2 Step-by-Step Test Procedure
Provide a reproducible testing flow:
1. Initial setup
2. Input construction
3. Iterative refinement
4. Success indicators

Avoid publishing exploit payloads that meaningfully enable abuse outside defensive testing.

---

## 5. Example Test Inputs

Provide **illustrative examples**:
- Prompt structures
- Input patterns
- Interaction flows

Use redaction or abstraction where appropriate.

---

## 6. Expected Outcomes

Define:
- What success looks like for the attacker
- Partial success indicators
- Failure conditions

---

## 7. Security Impact

Describe potential consequences:
- Data exposure
- Integrity compromise
- Unauthorized actions
- Regulatory or compliance risk

Map impact to business and operational risk.

---

## 8. Detection and Monitoring Signals

Identify signals defenders should monitor:
- Logs
- Anomalous input/output patterns
- Behavioral deviations
- Tool misuse indicators

---

## 9. Mitigations and Defensive Controls

List practical controls:
- Preventive controls
- Detective controls
- Compensating controls

Include architectural, procedural, and monitoring recommendations.

---

## 10. Validation and Retesting

Explain how to:
- Validate mitigations
- Re-test after fixes
- Integrate into continuous security testing

---

## 11. Related Risks and References

- SnowcrashAI Top 10 mappings (e.g., A01, A06)
- External research (if applicable)

---

## 12. Notes and Limitations

Document:
- Known limitations
- False positives
- Context-specific considerations
