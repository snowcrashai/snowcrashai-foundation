# SnowcrashAI Top 10 AI Security Risks

The SnowcrashAI Top 10 identifies the most critical and commonly observed security risks affecting modern AI systems, including machine learning pipelines, large language models (LLMs), retrieval-augmented generation (RAG), and AI agents.

This list is designed for:
- Security practitioners
- Red and blue teams
- Architects and defenders
- Risk and assurance teams

The focus is on **real attack paths, security impact, and defensive relevance**, not theoretical or purely ethical concerns.

---

## Versioning

- **Current version:** v0.1 (Initial practitioner draft)
- This list will evolve based on community feedback, field observations, and emerging attack techniques.

---

## The SnowcrashAI Top 10 (v0.1)

1. **Prompt Injection and Instruction Hijacking**
2. **Training Data Poisoning**
3. **Model Extraction and Weight Theft**
4. **Sensitive Data Leakage via Inference**
5. **Tool and Agent Abuse**
6. **RAG Knowledge Base Poisoning**
7. **AI Supply Chain Compromise**
8. **Unauthorized Fine-Tuning and Shadow AI**
9. **Model Drift Leading to Security Regression**
10. **Lack of Explainability and Assurance in High-Risk Decisions**

Each risk includes:
- Description
- Impact
- Example attack scenarios
- Detection and mitigation considerations
