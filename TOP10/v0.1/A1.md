# A01: Prompt Injection and Instruction Hijacking

## Description
Prompt injection occurs when an attacker manipulates model inputs to override, bypass, or subvert system instructions, guardrails, or intended behavior.

## Impact
- Unauthorized actions
- Policy bypass
- Data exposure
- Agent misuse

## Example Scenarios
- User-crafted prompts overriding system messages
- Indirect prompt injection via documents or web content
- Instruction leakage through chain-of-thought manipulation

## Detection and Mitigation
- Input sanitization and context separation
- Instruction hierarchy enforcement
- Output validation and policy checks
- Logging and anomaly detection on prompt patterns
